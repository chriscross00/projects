---
title: "read_format_wq_data"
author: "Christoper Chan"
date: "March 19, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
library(here)
library(tidyverse)
library(rowr)
```

Setting the working dir
```{r}
here()
```

Skip=1 is required because each csv has a Plot_title as the first row. I need to cbind, not make a single csv
I'll need to modify this when I read all the dir. This reads date subdir individually.
```{r}
create_date_df <- function(path) {
  # Recursively reads csv files and binds them to each other column-wise
  #
  # Args:
  #   path(object): A specified directory to read
  #
  # Returns:
  #   combined_df(dataframe): A dataframe with all csv's columns appended
  my_files <- 
    list.files(path,
               pattern = '*.csv',
               full.names = TRUE,
               recursive = TRUE) 
  combined_df <- data.frame()
  
  for (file in my_files){
    temp <- read_csv(file, skip=1)
    combined_df <- cbind.fill(combined_df, temp, fill=NA)

  }
  return(combined_df)
}
```

```{r}
clean_date_df <- function(df) {
  # Removes duplicate columns from dataframe, shortens names and changes factors to numeric when appropriate
  #
  # Args:
  #   df(dataframe): A dataframe with duplicate indexes and times
  #
  # Returns:
  #   df(dataframe): A cleaned dataframe ready for feature engineering
  df <- df[c(2:5, 8, 9, 12, 13)]
  names(df) <- c('obs', 'date_time', 'surface_pressure', 'air_temp1', 'salinity', 'sal_temp2', 'depth_pressure', 'depth_temp')
  df <- drop_na(df)
  
  # Converts factors to doubles 
  for (i in list(3, 4, 7, 8)){
    df[, i] <- as.numeric(levels(df[, i]))[df[, i]]
  }
  return(df)
}
```

```{r}
create_level <- function(df) {
  # Creates the water level in meters, converting the difference of air pressure and depth pressure
  #
  # Args:
  #   df(dataframe): A dataframe with duplicate indexes and times
  #
  # Returns:
  #   df(dataframe): A dataframe ready for a ARIMA model
  conv_factor = 0.013595100263597
  mutate(df, level_m = conv_factor*(df[, 7] - df[, 3]))
}
```

Test run


```{r}
create_arima_ready <- function(path) {
  # A helper function that wraps the creation and cleaning of a dataframe
  #
  # Args:
  #   path(object): A specified directory to read
  #
  # Returns:
  #   ready_df(dataframe): A dataframe ready for a ARIMA model
  ready_df <- path %>%
    create_date_df() %>%
    clean_date_df() %>%
    create_level()
  
  return(ready_df)
}
```

Okay, so i need to label each output CSV. I can do this by parsing the name of each input.
```{r, message=FALSE}
test_path <- 'working_data/180530 Logger Data/'
test1 <- create_arima_ready(test_path)

head(test1)

write_csv(test1, path = 'test12345.csv')
```

Correctly parses some of the data
```{r}
whole_dir <- function(path) {
  csv <- list.files(path, full.names = TRUE)
  test5 <- lapply(csv, create_arima_ready)
  return(test5)
}

a <- list.files('./working_data/', full.names = TRUE)

test5 <- list()
for (i in a){
  test5[[i]] <- create_arima_ready(i)
}

test5
```


```{r}
whole_dir <- function(path) {
  csv <- list.files(path, full.names = TRUE)
  test5 <- lapply(csv, create_arima_ready)
  return(test5)
}

b <- './working_data/'

abc <- whole_dir(b)


abc
```



