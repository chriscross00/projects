---
title: "read_format_wq_data"
author: "Christoper Chan"
date: "March 19, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
library(here)
library(tidyverse)
```

Setting the working dir
```{r}
here()
```

Skip=1 is required because each csv has a Plot_title as the first row. I need to cbind, not make a single csv
```{r}
my_files <- 
  list.files('working_data/180530 Logger Data/',
             pattern = '*.csv',
             full.names = TRUE,
             recursive = TRUE) %>%
  map_df(~read_csv(., col_types = cols(.default = 'c'), skip=1)) %>%
  set_names(c('obs', 'date_time', 'surface_pressure', 'air_temp1', 'salinity', 'sal_temp2', 'depth_pressure', 'depth_temp')) %>%
  gather(key, value, -date_time) %>%
  spread(key, value)

View(my_files)
```


This works!
```{r}
my_files <- 
  list.files('working_data/180530 Logger Data/',
             pattern = '*.csv',
             full.names = TRUE,
             recursive = TRUE) 
test_data <- data.frame()
for (file in my_files){
  temp <- read_csv(file, skip=1)
  test_data <- cbind.fill(test_data, temp, fill=NA)
}
View(test_data)
```

I'll need to modify this when I read all the dir. This reads date subdir individually.
```{r}
create_date_df <- function(path) {
  # Recursively reads csv files and binds them to each other column-wise
  #
  # Args:
  #   path(object): A specified directory to read
  #
  # Returns:
  #   combined_df(dataframe): A dataframe with all csv's columns appended
  my_files <- 
    list.files(path,
               pattern = '*.csv',
               full.names = TRUE,
               recursive = TRUE) 
  combined_df <- data.frame()
  
  for (file in my_files){
    temp <- read_csv(file, skip=1)
    combined_df <- cbind.fill(combined_df, temp, fill=NA)

  }
  return(combined_df)
}
```


```{r}
test_path <- 'working_data/180530 Logger Data/'

test1 <- create_date_df(test_path)
test1 <- clean_date_df(test1)


head(test1)
```

```{r}
clean_date_df <- function(df) {
  # Removes duplicate columns from dataframe, shortens names and changes factors to numeric when appropriate
  #
  # Args:
  #   df(dataframe): A dataframe with duplicate indexes and times
  #
  # Returns:
  #   df(dataframe): A cleaned dataframe ready for feature engineering
  df <- df[c(2:5, 8, 9, 12, 13)]
  names(df) <- c('obs', 'date_time', 'surface_pressure', 'air_temp1', 'salinity', 'sal_temp2', 'depth_pressure', 'depth_temp')
  
  # Converts factors to doubles 
  for (i in list(3, 4, 7, 8)){
    df[, i] <- as.numeric(levels(df[, i]))[df[, i]]
  }
  return(df)
}
```

Process:
- Read the csv from each subdir
  read.files('working_data/', pattern='*.csv', recursive=TRUE)
- cbind for each date
- calculate water level from change in pressure
- return final csv

for (date_subdir in data) {
  for (subdir in date_subdir){
    subdir <- read_csv(csv)
    cb
  }
}

Output: csv with water level and other wq data
