---
title: "read_format_wq_data"
author: "Christoper Chan"
date: "March 19, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
library(here)
library(tidyverse)
```

Setting the working dir
```{r}
here()
```

Skip=1 is required because each csv has a Plot_title as the first row. I need to cbind, not make a single csv
```{r}
my_files <- 
  list.files('working_data/180530 Logger Data/',
             pattern = '*.csv',
             full.names = TRUE,
             recursive = TRUE) %>%
  map_df(~read_csv(., col_types = cols(.default = 'c'), skip=1)) %>%
  set_names(c('obs', 'date_time', 'surface_pressure', 'air_temp1', 'salinity', 'sal_temp2', 'depth_pressure', 'depth_temp')) %>%
  gather(key, value, -date_time) %>%
  spread(key, value)

View(my_files)
```


This works!
```{r}
my_files <- 
  list.files('working_data/180530 Logger Data/',
             pattern = '*.csv',
             full.names = TRUE,
             recursive = TRUE) 

my_files

test_data <- data.frame()
for (file in my_files){
  temp <- read_csv(file, skip=1)
  test_data <- cbind.fill(test_data, temp, fill=NA)
}

View(test_data)

```

https://serialmentor.com/blog/2016/6/13/reading-and-combining-many-tidy-data-files-in-R
```{r}
data <- 
  list.files('working_data/180530 Logger Data/',
                            pattern = '*.csv',
                            full.names = TRUE,
                            recursive = TRUE) %>%
  map(read_csv) %>%
  reduce(cbind.fill)
View(data)
```


Process:
- Read the csv from each subdir
  read.files('working_data/', pattern='*.csv', recursive=TRUE)
- cbind for each date
- calculate water level from change in pressure
- return final csv

for (date_subdir in data) {
  for (subdir in date_subdir){
    subdir <- read_csv(csv)
    cb
  }
}

Output: csv with water level and other wq data
